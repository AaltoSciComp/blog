<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Posts in triton &#8212; Aalto Scientific Computing Blog  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <script src="../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../../_static/documentation_options.js?v=187304be"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script data-domain="aaltoscicomp.github.io" defer="defer" src="https://plausible.cs.aalto.fi/js/script.js"></script>
    <link rel="icon" href="../../../_static/logo-hexagons-02-compact.svg.ico"/>
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" /> 
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  
 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../blog/atom.xml"
  title="Posts in triton"
/>
  
  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
             
<div class="section ablog__collection">
  <h1>
    
    <span
      >Posts in  triton 
    </span>
  </h1>
   
  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../../2024/how-busy-is-the-cluster/">How busy is the cluster?  A discussion</a>
    </h2>
    <ul class="ablog-archive">
      <li>
         
        <span>2024 Oct 21</span>
        
      </li>
      <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Author: 
    </span>
     
    <a href="../../author/richard-darst/">Richard Darst</a>
      
  </li>
     
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Category: 
    </span>
     
    <a href="#">triton</a>
      
  </li>
    
</div>
    </ul>
    <p class="ablog-post-excerpt"><p>We occasionally get some questions: how busy is the cluster?  How
long do I have to wait?  Is there some dashboard that can tell me?</p>
<p>The answer is, unfortunately, not so easy.  <a class="reference external" href="https://scicomp.aalto.fi/triton/" title="(in Aalto Scientific Computing)"><span class="xref std std-doc">Our cluster</span></a> uses dynamic scheduling with a fairshare algorithm.
All users have a fairshare priority, which decreases the more you have
recently run.  Jobs are ranked by priority (including fairshare plus
other factors), and scheduled in that order.  If there are
unschedulable holes between those jobs, it can take a job with a lower
priority and fill them in (“backfilling”).  So that gives us:</p>
<p>A small-enough job with a low priority might still be scheduled
soon.</p>
<p>A higher priority user could submit something while you are waiting,
and increase your wait time.</p>
<p>An existing job could end early, making other wait times shorter.</p>
<p>An existing job could end early, allowing some other higher priority
jobs to run sooner, making backfilled jobs run later.</p>
<p>In short: there is no way to give an estimate of the wait time, in the
way people want.  We’ve tried but haven’t find a way to answer the
question well.</p>
<p>What can we know?</p>
<p>You can compare your fairshare factor with other users.  If you run
<code class="docutils literal notranslate"><span class="pre">sshare</span></code> you can see the fairshare (higher means higher priority).
<code class="docutils literal notranslate"><span class="pre">sprio</span></code> shows relatively priority for all jobs (here, the raw values
are multiplied by some factor and added).  On Triton (the new install
since 2024 may), they mean the following:</p>
<p>at 7 days) (zero when first submitted, increasing to 10000 at 7
days old)</p>
<p>The fairshare factor is “1e7 × FairShare priority from sshare”</p>
<p>The FairShare value is computed based on the raw usage value: at
each level of the share tree, it divides it up among the users so
that those who have run less have a higher priority.</p>
<p>The usage value decays with a two-week half life.</p>
<p>The others are mostly constant.</p>
<p>Still: this is all very abstract and what others submit has more
effect than your priority.  The only thing you can control is using
less resources.</p>
<p>This is quite cluster dependent so we’d recommend asking for help for
how your own cluster is setup.</p>
<p>This may be your real question. There are two main things:</p>
<p>Use less resources.  <strong>Make sure you don’t over-request more than
you need (CPU, memory, GPUs)</strong> - this will affect your future
fairshare less. Of course, use everything you need, “saving for
later” doesn’t give you more resources than you save now.</p>
<p>Request less resources per job.  This will let you be backfilled
into the scheduling holes (see below).</p>
<p>In this case, if there is a slot for you, you are scheduled very soon.
<code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">--test</span> <span class="pre">[RESOURCE_REQUESTS]</span></code> might give you some hint about
when a job would be scheduled - it basically tries to schedule an
empty job and reports the currently estimated start time. (It uses a
JobID though so don’t run it in a loop)</p>
<p>In this case, nothing can be said since the queue is always being
re-shuffled.  In the long-run, you get a fair share of resources.  If
you haven’t used much lately, you have more now.  Your wait time
depends more on what other users submit (and their priorities) than
what you submit - and this is always changing.  You can tell something
about how soon you’d be scheduled by looking at your priority relative
to other users.  Make your jobs as small and efficient as possible to
fit in between the holes of other jobs and get scheduled as soon as
possible.  If you can break one big job into smaller pieces (less
time, less CPU, less memory) that depend on each other, then you can
better fit in between all of the big jobs.  See the <a class="reference external" href="https://coderefinery.github.io/TTT4HPC_resource_management/scheduling/">Tetris metaphor
here in TTT4HPC</a></p>
<p>If your need is “run stuff quickly for testing”, make sure the jobs
are as short as possible.  Hopefully, your cluster staff about
development or debugging partitions that may be of use, because that’s
the solution for quick tests.</p>
<p>This description was in an old version of our docs but has since been
removed.  The exact values are out of date.  It’s included here for
detailed reference anyway:</p>
<p>Triton queues are not first-in first-out, but “fairshare”.  This means
that every person has a priority.  The more you run the lower your
user priority.  As time passes, your user priority increases again.
The longer a job waits in the queue, the higher its job priority goes.
So, in the long run (if everyone is submitting an never-ending stream
of jobs), everyone will get exactly their share.</p>
<p>Once there are priorities, then: jobs are scheduled in order of
priority, then any gaps are backfilled with any smaller jobs that can
fit in.  So small jobs usually get scheduled fast regardless.</p>
<p><em>Warning: from this point on, we get more and more technical, if you
really want to know the details.  Summary at the end.</em></p>
<p>What’s a share?  Currently shares are based on department and their
respective funding of Triton (<code class="docutils literal notranslate"><span class="pre">sshare</span></code>).  It used to be that
departments had a share, and then each member had a share of that
department.  But for complex reasons we have changed it so that it’s
flat: so that each person has a share, and the shares of everyone in a
department corresponds to that department’s share.  When you are below
your share (relative to everyone else), you have higher priority, and
vice versa.</p>
<p>Your priority goes down via the “job billing”: roughly time×power.
CPUs are billed at 1/s (but older, less powerful CPUs cost less!).
Memory costs .2/GB/s.  But: you only get billed for the max of memory
or CPU. So if you use one CPU and all the memory (so that no one else
can run on it), you get billed for all memory but no CPU.  Same for
all CPUs and little memory.  This encourages balanced use.  (this also
applies to GPUs).</p>
<p>GPUs also have a billing weight, currently tens of times higher than a
CPU billing weight for the newest GPUs.  (In general all of these can
change, for the latest info see search <code class="docutils literal notranslate"><span class="pre">BillingWeights</span></code> in
<code class="docutils literal notranslate"><span class="pre">/etc/slurm/slurm.conf</span></code>).</p>
<p>If you submit a long job but it ends early, you are only billed for
the actual time you use (but the longer job might take longer to start
at the beginning).  Memory is always billed for the full reservation
even if you use less, since it isn’t shared.</p>
<p>The “user priority” is actually just a record how much you have
consumed lately (the billing numbers above).  This number goes down
with a half-life decay of 2 weeks.  Your personal priority your share
compared to that, so we get the effect described above: the more you
(or your department) runs lately, the lower your priority.</p>
<p>If you want your stuff to run faster, the best way is to more
accurately specify your time (may make that job can find a place
sooner) and memory (avoids needlessly wasting your priority).</p>
<p>While your job is pending in the queue SLURM checks those metrics
regularly and recalculates job priority constantly.  If you are
interested in details, take a look at <a class="reference external" href="https://slurm.schedmd.com/priority_multifactor.html">multifactor priority plugin</a> page (general
info) and <a class="reference external" href="https://slurm.schedmd.com/priority_multifactor3.html">depth-oblivious fair-share factor</a> for what we
use specifically (warning: very in depth page).  On Triton, you can
always see the latest billing weights in <code class="docutils literal notranslate"><span class="pre">/etc/slurm/slurm.conf</span></code></p>
<p>Numerically, job priorities range from 0 to 2^32-1.  Higher is
sooner to run, but really the number doesn’t mean much itself.</p>
<p>These commands can show you information about your user and job
priorities:</p>
<p><code class="docutils literal notranslate"><span class="pre">slurm</span> <span class="pre">s</span></code></p>
<p>list of jobs per user with their current priorities</p>
<p><code class="docutils literal notranslate"><span class="pre">slurm</span> <span class="pre">full</span></code></p>
<p>as above but almost all of the job parameters are listed</p>
<p><code class="docutils literal notranslate"><span class="pre">slurm</span> <span class="pre">shares</span></code></p>
<p>displays usage (RawUsage) and current FairShare weights (FairShare, higher is better) values for all users</p>
<p><code class="docutils literal notranslate"><span class="pre">sshare</span></code></p>
<p>Raw data of the above</p>
<p><code class="docutils literal notranslate"><span class="pre">sprio</span></code></p>
<p>Raw priority of queued jobs</p>
<p><code class="docutils literal notranslate"><span class="pre">slurm</span> <span class="pre">j</span> <span class="pre">&lt;jobid&gt;</span></code></p>
<p>shows <code class="docutils literal notranslate"><span class="pre">&lt;jobid&gt;</span></code> detailed info including priority, requested nodes etc.</p>
<p>tl;dr: Just select the resources you think you need, and Slurm
tries to balance things out so everyone gets their share.  The best
way to maintain high priority is to use resources efficiently so you
don’t need to over-request.</p>
</p>

    <p class="ablog-post-expand">
      <a href="../../../2024/how-busy-is-the-cluster/"><em>Read more ...</em></a>
    </p>
    <hr />
  </div>
  
  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../../2024/triton-v3-is-now-default/">Triton v3 is now default</a>
    </h2>
    <ul class="ablog-archive">
      <li>
         
        <span>2024 May 06</span>
        
      </li>
      <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Author: 
    </span>
     
    <a href="../../author/richard-darst/">Richard Darst</a>
      
  </li>
     
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Category: 
    </span>
     
    <a href="#">triton</a>
      
  </li>
    
</div>
    </ul>
    <p class="ablog-post-excerpt"><p>Triton has a major update.  You can read our previous info about this at
<a class="reference internal" href="../../../2023/preparing-for-new-triton/"><span class="doc">Preparing for new Triton</span></a>, and our “what has changed” in
<a class="reference external" href="https://version.aalto.fi/gitlab/AaltoScienceIT/triton/-/issues/1593">Triton issue #1593</a>.</p>
<p>You might get <a class="reference internal" href="../../../2024/ssh-host-key-warnings/"><span class="doc">SSH host key warnings</span></a>.</p>
<p>It has the same name, and importantly the same user accounts and data,
but all the software and operating system is changed.  In particular:</p>
<p>All software modules are different</p>
<p>Any software which has been complied will need to be re-compiled.</p>
<p>Triton’s previous operating system was released in 2014.  Security
support runs out at the end of 2024 May, and it <em>has</em> to be updated.
Stability is good for research, so we try to reduce the number of
changes (compare)</p>
<p>We realize that a change is very disruptive and painful, especially
since the expectation is that Triton never changes.  But an old
operating system makes problem for users too, and they have gotten
more and more over the years.</p>
<p>Most of the transition for different types of software is described in
<a class="reference external" href="https://version.aalto.fi/gitlab/AaltoScienceIT/triton/-/issues/1593">Triton issue #1593</a>.</p>
</p>

    <p class="ablog-post-expand">
      <a href="../../../2024/triton-v3-is-now-default/"><em>Read more ...</em></a>
    </p>
    <hr />
  </div>
  
  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../../2024/ssh-host-key-warnings/">Triton v3 SSH host key warnings</a>
    </h2>
    <ul class="ablog-archive">
      <li>
         
        <span>2024 May 06</span>
        
      </li>
      <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Author: 
    </span>
     
    <a href="../../author/richard-darst/">Richard Darst</a>
      
  </li>
     
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Category: 
    </span>
     
    <a href="#">triton</a>
      
  </li>
    
</div>
    </ul>
    <p class="ablog-post-excerpt"><p>When updating Triton, many users will get a message like this (or
similar things if you use other SSH clients like PuTTY):</p>
<p>SSH (Secure SHell) is made to be secure, and that means one it
verifies the server you are connecting <strong>to</strong> via its <strong>ssh host
key</strong>.  The representation of this key is the <strong>fingerprint</strong>, like
<code class="docutils literal notranslate"><span class="pre">SHA256:OqCehC2lbHdl8mYGI/G9vlxTwew3H3KrvxKDkwIQy9Y</span></code>.  This means
that the NSA or someone can’t intercept the connecting and get your
password by pretending to be Triton.  This is a good thing.</p>
<p>OpenSSH (the command line program on Linux, MacOS, Windows) saves
these connection IDs (fingerprints) in
<code class="docutils literal notranslate"><span class="pre">$HOME/.ssh/known_hosts</span></code>.  Other programs may store the keys
somewhere else.</p>
<p>The warning looks scary but the first thing to ask is “should the
server I am connecting to have changed?”.  If you have been directed
to this blog post, then probably yes, it has.  You should <em>always</em>
think if the fingerprint should change, and if there is no reason for
them to have changed, contact your administrators.  You can usually
verify the keys online, for example
<a class="reference external" href="https://scicomp.aalto.fi/triton/usage/ssh-fingerprints/" title="(in Aalto Scientific Computing)"><span>Triton ssh key fingerprints</span></a>.</p>
<p>If you are on command line OpenSSH (Linux), it will propose a command
that will remove the old host key:</p>
<p>For other programs, follow whatever prompts it might give to replace
the host key fingerprint.</p>
<p>When you get a “The authenticity of host ‘triton.aalto.fi’ can’t be
established”, verify the SSH key fingerprints that are presented, then
click “yes” to permanently save them (until they change next, they can
always be updated).  The fingerprints for Triton v3 are:</p>
</p>

    <p class="ablog-post-expand">
      <a href="../../../2024/ssh-host-key-warnings/"><em>Read more ...</em></a>
    </p>
    <hr />
  </div>
  
  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../../2023/webp-security-vulnerability/">libwebp security vulnerability and computational scientists</a>
    </h2>
    <ul class="ablog-archive">
      <li>
         
        <span>2023 Sep 28</span>
        
      </li>
      <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Author: 
    </span>
     
    <a href="../../author/richard-darst/">Richard Darst</a>
      
  </li>
     
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Category: 
    </span>
     
    <a href="#">triton</a>
     ,    
    <a href="../security/">security</a>
      
  </li>
    
</div>
    </ul>
    <p class="ablog-post-excerpt"><p>Recently, a <a class="reference external" href="https://blog.isosceles.com/the-webp-0day/">major security vulnerability (CVE-2023-5129)</a> has been
found in <code class="docutils literal notranslate"><span class="pre">libwebp</span></code>, an image decoding library for the <cite>.webp</cite> format.
This is major, since this library is embedded in many apps and web
browsers and allows remote code execution just by opening a file.  For
computational scientists, there is still some impact - and it’s harder
to compensate for.  In short, just by processing an image in the .webp
format, someone can take over your computer or session.</p>
<p><code class="docutils literal notranslate"><span class="pre">libwebp</span></code> is the current issue, but the problem is general:
<strong>computational scientists often create software environments and use
them for a long
time.  These environments aren’t usually browsing the web (the most
likely attack vector here), but they do involve lots of code installed
from different projects.  How does one manage security in this case?</strong></p>
<p><em>This post may be updated</em></p>
<p>If you use web browsers or apps on your own desktops, laptops, phones,
etc. - make sure update them!</p>
<p>If you don’t use images in your research, there probably isn’t much
impact.</p>
<p>If you <em>do</em>, this is what could happen:</p>
<p>You make a Python / Anaconda environment which uses <cite>libwebp</cite>
somehow - directly installed through Conda, or some other
application.</p>
<p>You download a dataset containing images.  You process them as part
of your research with the old environment.</p>
<p>The malicious image runs an exploit.  It has access to your whole
user account on that computer: extract any data, add SSH keys for
remote access, corrupt/delete data (which might not be backed up
from the cluster…).</p>
<p>Many things have to happen here, but it’s very possible for it to
happen.  You could <strong>lose access to non-backed up data or code</strong> or
<strong>other confidential or sensitive data could be compromised</strong>, since
code from one project from your user account has access to all
projects from your account.</p>
<p>One would normally fix things by updating software.  But when you are
dealing with a research environment that can’t easily be updated, what
should you do?  This is the real question here.</p>
<p>It’s a multi-layered problem, and the answer will depend on your
work.  <strong>libwebp is what we are thinking about now, but the problem is
general: there are other security problems that occasionally come up
that can affect more scientific code.  How do you prepare for next time?</strong></p>
<p>Update your environments (conda, virtualenv, etc).  You could try to
see if <code class="docutils literal notranslate"><span class="pre">libwebp</span></code> is inside of them (<code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">list</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">webp</span></code>),
but especially for Pip packages it might not be apparent.</p>
<p>Make your environments reproducible: If you define your dependencies
in <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> (Python), <code class="docutils literal notranslate"><span class="pre">environment.yml</span></code> (conda), or
whatever is suitable for your language, you can easily re-generate
environments to bring everything up to date.  (delete old one,
re-create).</p>
<p>If you pin versions of dependencies (like <code class="docutils literal notranslate"><span class="pre">numpy==1.20.0</span></code>), it’s
possible it can pull in older versions of other dependencies.</p>
<p>Containerize your workflows.  If code runs inside of a container, it
keeps it isolated from the rest of the operating system and user
account.  (but containers aren’t usually designed for strict
security, but it’s better than nothing).</p>
<p>If you use pre-built modules on the cluster, try not to use old
versions.  We’ll update some recent modules, but we can’t update all
of the old ones.  At least <code class="docutils literal notranslate"><span class="pre">webp</span></code> is in the default <code class="docutils literal notranslate"><span class="pre">anaconda</span></code>
modules.</p>
<p>If you write or maintain software in general, keep it up to date as
much as reasonable!  Don’t make others get into a place where they
are having to use old versions of libraries to make it work.</p>
<p>In general, think about your dependencies.  Be at least a little bit
suspicious before you install random other software, that may
possibly pull in lots of other dependencies.  Of course, as a
researcher, you may not have much choice.</p>
<p>These commands seem to be able to update an environment to a newer
libwebp.  It <em>seems</em> to work on newer environments, but we don’t know
for sure.  Instead of <code class="docutils literal notranslate"><span class="pre">mamba</span></code>, <code class="docutils literal notranslate"><span class="pre">conda</span></code> in theory works but is to
slow it may not be practical:</p>
<p>There is a major security vulnerability in <code class="docutils literal notranslate"><span class="pre">libwebp</span></code>.  While the
impact on computational scientists may not be <em>that</em> much, a bigger
issue is the difficulty of keeping all of the environments up to date
so that next time this happens, it’s easier to respond.</p>
<p>We hope to have more security recommendations for computational
scientists in the future.  If anyone is interested in collaborating on
this, let us know.</p>
<p>Common apps which embed Chrome or libwebp: Chrome, Firefox, VSCode,
Zulip, Slack, Discord… things that use Electron to embed a web
browser are affected, and that’s <em>many</em> things.</p>
</p>

    <p class="ablog-post-expand">
      <a href="../../../2023/webp-security-vulnerability/"><em>Read more ...</em></a>
    </p>
    <hr />
  </div>
  
  <div class="section ablog-post">
    <h2 class="ablog-post-title">
      <a href="../../../2023/preparing-for-new-triton/">Preparing for new Triton</a>
    </h2>
    <ul class="ablog-archive">
      <li>
         
        <span>2023 Sep 12</span>
        
      </li>
      <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Author: 
    </span>
     
    <a href="../../author/richard-darst/">Richard Darst</a>
      
  </li>
     
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Category: 
    </span>
     
    <a href="#">triton</a>
      
  </li>
    
</div>
    </ul>
    <p class="ablog-post-excerpt"><p>Sometime in autumn of 2023 (e.g. October/November), we will do a major
update of Triton: updating the basic operating system, and thus almost
everything else.  There are big benefits to this: newer basic
operating system software, but also such a basic update affects almost
every user.  <strong>For a short time, this will make a lot of work for almost
every user.  This post gives advance warning and a chance of feedback
of how to make the update most usable.</strong></p>
<p>This post is just advance warning and things to prepare already.  All
actual instructions will come later.</p>
<p>We will update the basic operating system from CentOS 7 to something
else (Red Hat 9).  We’ve ordered all new management hardware
to make the backend more reliable and manageable.  Along with this
comes with an update of the software build system, which should allow
us to deploy software to our users even better.  We’ll also update our
configuration management system for more reproducibility.</p>
<p>We also hope to think about the usability of the new system: remove a
lot of old options and add in new, simpler ways of doing what people
need.</p>
<p>All data and storage will remain the same, so there <strong>is no big data
migration needed.</strong></p>
<p>The old and new clusters will be accessible at the same time (two
different login nodes), with the same filesystems mounted (same data
available) and some compute resources still available there, so that
people can slowly migrate.  But the old one won’t stay running too
long, to avoid long maintenance effort or splitting of the resources.</p>
<p>The biggest problem with big cluster updates like this is
<strong>reproducibility</strong>: does you work from a month ago still work in one
month?  If not, this is a big problem.  It’s even worse if there is a
much longer gap before you come back to it (paper revisions, anyone?).</p>
<p>You could say there are two things that can go wrong with a cluster upgrade or change:</p>
<p><strong>Specific software/code that needs to be compiled and installed:</strong>
Software needs re-compiling for new clusters or new cluster OS updates.</p>
<p><strong>Whole workflows:</strong> you need to make all the pieces work together.
Different paths and workflow managers may need updating.</p>
<p>What you can do:</p>
<p>Manage any messes you have earlier rather than later.  It’s better
if you slowly clean up over time, so you can focus on the
differences once the change happens.</p>
<p>Know what software you are using.  It’s easier for us to re-install something we
have already installed when someone can tell us the exact name and version
that they are using.</p>
<p><a class="reference external" href="https://coderefinery.github.io/testing/">Tests for your software</a>.  Some way to validate
that it works correctly.</p>
<p>Contact <a class="reference external" href="https://scicomp.aalto.fi/rse/">Aalto RSE</a> for hands-on
help supporting the transition.  Come to the <a class="reference external" href="https://scicomp.aalto.fi/help/garage/">garage</a> early and often.</p>
<p>If there are any annoyances about Triton that you’d like us to
consider for the upgrade, now is the time to let us know so we can
plan them.  <strong>We especially value feedback on usability problems.</strong></p>
<p>Discuss with us in <a class="reference external" href="https://scicomp.zulip.cs.aalto.fi/#narrow/stream/6-triton/topic/feedback.on.new.Triton">our chat</a>,
or <a class="reference external" href="https://version.aalto.fi/gitlab/AaltoScienceIT/triton/issues/">open a Triton issue</a>.</p>
<p><em>This post has been updated with minor corrections, changes be found in
git history.</em></p>
</p>

    <p class="ablog-post-expand">
      <a href="../../../2023/preparing-for-new-triton/"><em>Read more ...</em></a>
    </p>
    <hr />
  </div>
   
</div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper"><h1 style="text-align: center; margin-top: 0px">
  <a href="../../../">Aalto Scientific Computing Blog</a>
</h1>
<ul>
<li><a href="https://scicomp.aalto.fi">Home</a></li>
<li><a href="../../atom.xml">Blog feed</a></li>
<li><a href="https://fosstodon.org/@SciCompAalto">Mastodon</a></li>
<li><a href="https://twitter.com/SciCompAalto">Twitter</a></li>
</ul>
<div class="ablog-sidebar-item ablog__recentposts">
  <h3>
    <a href="../../">Recent Posts</a>
  </h3>
  <ul>
     
    <li>
      <a href="../../../2025/ucl-rse-visit/">
        08 May - RSE report from visiting University College London Advanced Research Computing
      </a>
    </li>
    
    <li>
      <a href="../../../2024/what-is-a-rse/">
        20 November - What is a Research Software Engineer?
      </a>
    </li>
    
    <li>
      <a href="../../../2024/how-busy-is-the-cluster/">
        21 October - How busy is the cluster?  A discussion
      </a>
    </li>
    
    <li>
      <a href="../../../2024/rse-work-rotations/">
        08 October - RSE work rotations
      </a>
    </li>
    
    <li>
      <a href="../../../2024/rse-collaboration/">
        08 October - Future RSE collaboration in Finland
      </a>
    </li>
    
  </ul>
</div>

<div class="ablog-sidebar-item ablog__categories">
  <h3>
    <a href="../">Categories</a>
  </h3>
  <ul>
     
    <li>
      <a href="../ai/">AI (1)</a>
    </li>
      
    <li>
      <a href="../asc/">ASC (4)</a>
    </li>
      
    <li>
      <a href="../aalto/">aalto (1)</a>
    </li>
      
    <li>
      <a href="../python/">python (1)</a>
    </li>
      
    <li>
      <a href="../rse/">rse (6)</a>
    </li>
      
    <li>
      <a href="../security/">security (1)</a>
    </li>
      
    <li>
      <a href="../software/">software (1)</a>
    </li>
      
    <li>
      <a href="../ssh/">ssh (1)</a>
    </li>
      
    <li>
      <a href="../teaching/">teaching (2)</a>
    </li>
      
    <li>
      <a href="#">triton (5)</a>
    </li>
      
    <li>
      <a href="../whisper/">whisper (1)</a>
    </li>
     
  </ul>
</div>

<div class="ablog-sidebar-item ablog__archives">
  <h3>
    <a href="../../archive/">Archives</a>
  </h3>
  <ul>
     
    <li>
      <a href="../../2025/">2025 (1)</a>
    </li>
      
    <li>
      <a href="../../2024/">2024 (8)</a>
    </li>
      
    <li>
      <a href="../../2023/">2023 (9)</a>
    </li>
      
    <li>
      <a href="../../2021/">2021 (1)</a>
    </li>
     
  </ul>
</div>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2021-2023, Aalto Scientific Computing.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>